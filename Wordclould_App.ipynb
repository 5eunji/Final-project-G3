{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/5eunji/Final-project-G3/blob/main/Wordclould_App.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pre-Listening Activity: Learning New Words**\n",
        "##1. Gradio Wordcloud App: Create a word cloud from the text to highlight the most frequent words."
      ],
      "metadata": {
        "id": "aCIvfFOXKnfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib wordcloud nltk translate gradio pandas\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Define example sentences, synonyms, and Korean meanings for the word list\n",
        "word_data_examples = {\n",
        "   \"feud\": (\"The feud between the Montagues and Capulets caused much suffering.\", \"conflict, quarrel\", \"불화\", \"싸움\"),\n",
        "    \"family\": (\"The Montague family was Romeo’s family.\", \"household, kin\", \"가족\", \"가문\"),\n",
        "    \"party\": (\"Romeo secretly attended a Capulet party.\", \"gathering, celebration\", \"파티\", \"모임\"),\n",
        "    \"love\": (\"Their love was pure and strong.\", \"affection, passion\", \"사랑\", \"애정\"),\n",
        "    \"hate\": (\"The hate between the families was unending.\", \"anger, hostility\", \"증오\", \"미움\"),\n",
        "    \"window\": (\"Romeo stood below Juliet’s window.\", \"pane, opening\", \"창문\", \"유리창\"),\n",
        "    \"promise\": (\"Romeo promised to love Juliet forever.\", \"vow, pledge\", \"약속\", \"맹세\"),\n",
        "    \"secret\": (\"Their love remained a secret.\", \"hidden, private\", \"비밀\", \"숨겨진\"),\n",
        "    \"marry\": (\"They decided to marry despite their families’ feud.\", \"wed, unite\", \"결혼하다\", \"혼인하다\"),\n",
        "    \"tragedy\": (\"Romeo and Juliet is a story of tragedy and love.\", \"disaster, misfortune\", \"비극\", \"참사\")\n",
        "}\n",
        "\n",
        "# Words to be excluded from both the word cloud and the word list\n",
        "exclude_words = set([\n",
        "    'romeo', 'juliet', 'montague', 'capulet', 'oh', 'verona'\n",
        "])\n",
        "\n",
        "def get_wordnet_pos(treebank_tag):\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def process_text(text):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    words = [word.lower() for word in words if word.isalnum() and word.lower() not in stop_words and word.lower() not in exclude_words]\n",
        "    word_freq = Counter(words)\n",
        "    pos_tags = nltk.pos_tag(words)\n",
        "    return word_freq, pos_tags\n",
        "\n",
        "def generate_wordcloud(word_freq):\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freq)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.savefig('wordcloud.png')\n",
        "    return 'wordcloud.png'\n",
        "\n",
        "def translate_and_get_pos(word_freq, pos_tags):\n",
        "    pos_map = {\n",
        "        'NN': 'n.', 'NNS': 'n.', 'NNP': 'n.', 'NNPS': 'n.', 'VB': 'v.', 'VBD': 'v. (과거형)', 'VBG': 'v. (ing형)',\n",
        "        'VBN': 'v. (과거분사형/수동태)', 'VBP': 'v.', 'VBZ': 'v.', 'JJ': 'adj.', 'JJR': 'adj.', 'JJS': 'adj.',\n",
        "        'RB': 'adv.', 'RBR': 'adv.', 'RBS': 'adv.', 'IN': 'prep.', 'DT': 'det.', 'CC': 'conj.',\n",
        "        'UH': 'intj.'\n",
        "    }\n",
        "\n",
        "    seen_verbs = set()  # To track if we have already annotated specific verb forms\n",
        "    word_data = []\n",
        "    for word, freq in word_freq.items():\n",
        "        if word not in word_data_examples:\n",
        "            continue  # Skip if the word is not in the word_data_examples\n",
        "\n",
        "        pos_list = [pos_map.get(pos_tag[1], 'N/A') for pos_tag in pos_tags if pos_tag[0] == word and pos_tag[1] in pos_map]\n",
        "        pos_list = set(pos_list) if pos_list else {'N/A'}\n",
        "        if 'N/A' in pos_list or word in exclude_words:\n",
        "            continue  # Skip if no valid POS or excluded word\n",
        "        pos_str = \", \".join(pos_list)\n",
        "\n",
        "        # Check if the word is a specific verb form and get the base form\n",
        "        lemmatized_word = word\n",
        "        original_pos_tags = [pos_tag[1] for pos_tag in pos_tags if pos_tag[0] == word]\n",
        "        for pos_tag in original_pos_tags:\n",
        "            wn_pos = get_wordnet_pos(pos_tag)\n",
        "            if wn_pos == wordnet.VERB:\n",
        "                lemmatized_word = lemmatizer.lemmatize(word, wn_pos)\n",
        "                if word != lemmatized_word and lemmatized_word not in seen_verbs:\n",
        "                    if pos_tag.startswith('VBD'):\n",
        "                        pos_str += f\" (v. {lemmatized_word}의 과거형)\"\n",
        "                    elif pos_tag.startswith('VBG'):\n",
        "                        pos_str += f\" (v. {lemmatized_word}의 ing형)\"\n",
        "                    elif pos_tag.startswith('VBN'):\n",
        "                        pos_str += f\" (v. {lemmatized_word}의 과거분사형/수동태)\"\n",
        "                    seen_verbs.add(lemmatized_word)\n",
        "\n",
        "        translation = f\"{word_data_examples[word][2]}, {word_data_examples[word][3]}\"\n",
        "        example_sentence, synonyms = word_data_examples[word][:2]\n",
        "        word_data.append((word, pos_str, translation, example_sentence, synonyms))\n",
        "\n",
        "    # Sort the word data by frequency\n",
        "    word_data.sort(key=lambda x: word_freq[x[0]], reverse=True)\n",
        "\n",
        "    return word_data\n",
        "\n",
        "def main(text):\n",
        "    word_freq, pos_tags = process_text(text)\n",
        "    wordcloud_image = generate_wordcloud(word_freq)\n",
        "    word_data = translate_and_get_pos(word_freq, pos_tags)\n",
        "\n",
        "    # Create a DataFrame to display the word data in a table format\n",
        "    df = pd.DataFrame(word_data, columns=[\"어휘 (Word)\", \"범주 (Category)\", \"뜻 (Meaning)\", \"예문 (Example)\", \"동의어 (Synonyms)\"])\n",
        "    word_data_table = df.to_html(index=False, justify='center')\n",
        "\n",
        "    return wordcloud_image, word_data_table\n",
        "\n",
        "# Custom CSS for the Gradio interface\n",
        "css = \"\"\"\n",
        "<style>\n",
        "body {\n",
        "    background-color: skyblue !important;\n",
        "}\n",
        ".gr-button {\n",
        "    background-color: blue !important;\n",
        "    border-color: blue !important;\n",
        "}\n",
        "table {\n",
        "    width: 100%;\n",
        "    border-collapse: collapse;\n",
        "    text-align: center;\n",
        "}\n",
        "th, td {\n",
        "    padding: 8px;\n",
        "    border: 1px solid #ddd;\n",
        "}\n",
        "th {\n",
        "    background-color: #f2f2f2;\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "# Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=main,\n",
        "    inputs=\"text\",\n",
        "    outputs=[\"image\", \"html\"],\n",
        "    title=\"Wordcloud Vocabulary Learning App\",\n",
        "    description=\"Input text to generate a word cloud and a frequency list with Korean meanings, parts of speech, and example sentences.\"\n",
        "     \"<br><br><b>The full text:</b><br>\"\n",
        "     \"\"\"<blockquote>Many years ago, in the city of Verona, Italy, there were two families, the Montagues and the Capulets. These two families were always battling and did not like each other.\n",
        "\n",
        "One day, Romeo Montague secretly attended a Capulet party. There, he saw Juliet Capulet and instantly fell in love. However, their love was in danger because of their families’ feud. After the party, Romeo went to Juliet’s window, and they promised to love each other forever.\n",
        "\n",
        "Despite their love, the feud between their families grew worse. Their story is one of love, tragedy, and heartbreak.<br><br><i>Copy and paste to try.</i></blockquote>\"\"\",\n",
        ")\n",
        "\n",
        "# Launch the interface and include the custom CSS\n",
        "interface.launch()\n",
        "gr.HTML(css)\n",
        "\n"
      ],
      "metadata": {
        "id": "zzJ7HutiTFsT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}